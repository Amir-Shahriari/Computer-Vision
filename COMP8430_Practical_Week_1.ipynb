{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_h4F45N4-oC"
      },
      "source": [
        "# Advanced Image Classification with Lightweight CNN\n",
        "\n",
        "In this practical, we are aiming to establish an advanced image classification using a lightweight convolutional neural network (CNN) model trained on the CIFAR-10 dataset. Our task is to enable the model to include additional techniques such as data augmentation, optimizer and weight decay, learning rate scheduling,  model checkpointing, and evaluation of the best model on the test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atKBxsPn4-oE"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "1. Run each cell sequentially to execute the code.\n",
        "2. Make sure to read the comments provided in the code cells for additional information and instructions.\n",
        "3. Experiment with different hyperparameters, model architectures, and techniques to improve performance.\n",
        "4. Add your implementation for the four new features as instructed below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTaO3XEp4-oF",
        "outputId": "432bca2f-8a58-46ac-ae2e-4482a2b7bb80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoFJWZ9H4-oG"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i71h6An7gs4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f0ff17-bbee-468a-f448-b383be548a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import alexnet\n",
        "model_show = alexnet()\n",
        "print(model_show)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfWasDo84-oG"
      },
      "source": [
        "## Step 1: Data Preprocessing and Augmentation\n",
        "\n",
        "Load the CIFAR-10 dataset, apply transformations for data preprocessing and augmentation, and create data loaders for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_4h-kSxH4-oH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32fe4fde-8ffa-4172-d919-1ebb513fdbf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Define data transformations\n",
        "train_transform = transforms.Compose([\n",
        "    # Add data augmentation transformations here\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=data_augmentation)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDi58Ux24-oH"
      },
      "source": [
        "## Step 2: Define the Lightweight CNN Model\n",
        "\n",
        "Define a lightweight CNN model for image classification with additional layers and techniques for improved performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "d0ZBmLZT4-oH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50dfff83-9019-40b1-bf29-d593de2a1819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightweightCNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define the CNN model\n",
        "# Add your implementation here\n",
        "class LightweightCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LightweightCNN, self).__init__()\n",
        "        # Define the layers\n",
        "        # Add convolutional and fully connected layers here\n",
        "        # Use dropout for regularization\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass\n",
        "        # Implement forward pass through layers\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
        "        x = torch.flatten(x, 1)  # Flatten feature maps\n",
        "        x = self.dropout(nn.functional.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Create an instance of the lightweight CNN model\n",
        "model = LightweightCNN()\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm8n8NEz4-oH"
      },
      "source": [
        "## Step 3: Train the Model\n",
        "\n",
        "Train the lightweight CNN model using the training dataset with techniques such as learning rate scheduling and model checkpointing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Phnp7PA54-oI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8c46d0-d42a-4e96-a26d-8653d36a31e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.9913, Val Loss: 0.9090\n",
            "Epoch 2/10, Loss: 0.9556, Val Loss: 0.9129\n",
            "Epoch 3/10, Loss: 0.9238, Val Loss: 0.8837\n",
            "Epoch 4/10, Loss: 0.8976, Val Loss: 0.9081\n",
            "Epoch 5/10, Loss: 0.8825, Val Loss: 0.8364\n",
            "Epoch 6/10, Loss: 0.7837, Val Loss: 0.7707\n",
            "Epoch 7/10, Loss: 0.7683, Val Loss: 0.7538\n",
            "Epoch 8/10, Loss: 0.7575, Val Loss: 0.7521\n",
            "Epoch 9/10, Loss: 0.7508, Val Loss: 0.7555\n",
            "Epoch 10/10, Loss: 0.7425, Val Loss: 0.7566\n"
          ]
        }
      ],
      "source": [
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=0.001,\n",
        "    # Add weight decay here\n",
        "    weight_decay=1e-4\n",
        "    )\n",
        "# Try another optimizer here\n",
        "\n",
        "# Add your implementation for learning rate scheduling here\n",
        "# Define learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # Add your implementation here\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    # Add your implementation for learning rate scheduling here\n",
        "    # Add your implementation here\n",
        "    scheduler.step()\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}')\n",
        "    # Save the model if validation loss has decreased\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na5ih-534-oI"
      },
      "source": [
        "## Step 4: Evaluate the Model\n",
        "\n",
        "Evaluate the performance of the trained model on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "R9tJHMer4-oI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23d735e-7d3d-4d5b-98ad-b88e9257a695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-cb83b2f3860f>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  best_model.load_state_dict(torch.load('best_model.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 78.40%\n"
          ]
        }
      ],
      "source": [
        "# Load the best model\n",
        "best_model = LightweightCNN()\n",
        "best_model.load_state_dict(torch.load('best_model.pth'))\n",
        "best_model.to(device)\n",
        "\n",
        "# Evaluate the model\n",
        "best_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = best_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19SE7Gfa4-oI"
      },
      "source": [
        "## Step 5: Add New Features\n",
        "\n",
        "Add your implementation for the following new features:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p2rS4HB4-oI"
      },
      "source": [
        "### Feature 1: Data Augmentation\n",
        "\n",
        "Implement data augmentation techniques for the training data to improve model generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Hp3m_Iwb4-oI"
      },
      "outputs": [],
      "source": [
        "# Add your implementation for data augmentation here\n",
        "# Define data augmentation transformations for training data\n",
        "data_augmentation = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip images with 50% probability\n",
        "    transforms.RandomRotation(15),  # Rotate images by Â±15 degrees\n",
        "    transforms.RandomCrop(32, padding=4),  # Randomly crop with padding\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust colors\n",
        "    transforms.ToTensor(),  # Convert image to tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize pixel values\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHfvaM8V4-oJ"
      },
      "source": [
        "### Feature 2: Optimizer and Weight Decay\n",
        "\n",
        "Try training the model with a different optimizer to improve the model performance. Set a proper weight decay in the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30bI1H0O4-oJ"
      },
      "outputs": [],
      "source": [
        "# Add your implementation for optimizer and weight decay\n",
        "# Define the optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QizpuW2W4-oJ"
      },
      "source": [
        "### Feature 3: Learning Rate Scheduling\n",
        "\n",
        "Implement learning rate scheduling during training to adjust the learning rate based on the training progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_xZlcze4-oJ"
      },
      "outputs": [],
      "source": [
        "# Add your implementation for learning rate scheduling here\n",
        "# Define learning rate scheduler\n",
        "# Option 1: StepLR (Reduces LR every 5 epochs by a factor of 0.1)\n",
        "# scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "# Option 2: ReduceLROnPlateau (Reduces LR when val loss stops improving)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "# Option 3: CosineAnnealingLR (Smooth LR decay over epochs)\n",
        "# scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmU4GrUR4-oJ"
      },
      "source": [
        "### Feature 4: Model Checkpointing\n",
        "\n",
        "Implement model checkpointing during training to save the best model based on validation performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShHkQrQb4-oK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Define the path for saving the best model\n",
        "best_model_checkpoint = \"best_model.pth\"\n",
        "best_val_loss = float('inf')  # Initialize with a high loss\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Save the model if validation loss improves\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), best_model_checkpoint)\n",
        "        print(f\"Model saved at epoch {epoch+1} with val loss {val_loss:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvL1raJw4-oK"
      },
      "source": [
        "### Feature 5: Evaluation of the Best Model\n",
        "\n",
        "Evaluate the best model saved during training on the test dataset to report final performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE567PCq4-oK"
      },
      "outputs": [],
      "source": [
        "# Add your implementation for evaluation of the best model here\n",
        "# Load the best model\n",
        "best_model = LightweightCNN()\n",
        "best_model.load_state_dict(torch.load('best_model.pth'))\n",
        "best_model.to(device)\n",
        "\n",
        "# Evaluate the best model on the test dataset\n",
        "best_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = best_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
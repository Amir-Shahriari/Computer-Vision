{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset Definition for Deep Learning Classification\n",
    "\n",
    "## Task:\n",
    "\n",
    "Your task is to define a custom dataset for deep learning-based classification.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "Follow the steps below to define a custom dataset for classification:\n",
    "\n",
    "1. Create a new Python class inheriting from `torch.utils.data.Dataset`.\n",
    "2. Implement the `__init__` method to initialize the dataset.\n",
    "3. Implement the `__len__` method to return the total number of samples in the dataset.\n",
    "4. Implement the `__getitem__` method to return a sample and its corresponding label.\n",
    "5. Load and preprocess the data within the `__init__` method or within the `__getitem__` method.\n",
    "6. Return the sample and label in the `__getitem__` method.\n",
    "\n",
    "Once you have defined the custom dataset class, you can use it with PyTorch's DataLoader to load and iterate over the data during training or evaluation.\n",
    "\n",
    "In this practical session, we use another 10-category classification dataset STL-10. The processed STL-10 dataset can be downloaded from\n",
    "https://drive.google.com/file/d/18j4RTzC5uCqT6QV96-oa-FNGztfDx5oH/view?usp=drive_link\n",
    "\n",
    "Download and unzip the data, making the directory structure looks like\n",
    "```bash\n",
    ".\n",
    "├── COMP8430_Practical_Week_3.ipynb\n",
    "└── stl-10\n",
    "    ├── test_images\n",
    "    │    ├── test_image_png_1.png\n",
    "    │    ├── test_image_png_2.png\n",
    "    │    ├── test_image_png_3.png\n",
    "    │    └── ......\n",
    "    ├── test.json\n",
    "    ├── train_images\n",
    "    │    ├── train_image_png_1.png\n",
    "    │    ├── train_image_png_2.png\n",
    "    │    ├── train_image_png_3.png\n",
    "    │    └── ......\n",
    "    └── train.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install torch torchvision Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preprocessing and Augmentation\n",
    "\n",
    "Define the STL-10 dataset, apply transformations for data preprocessing and augmentation, and create data loaders for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import json\n",
    "from PIL import Image\n",
    "from os.path import join\n",
    "\n",
    "# Implement a Dataset to load the STL-10 dataset for training and evaluation\n",
    "class STL10(Dataset):\n",
    "    def __init__(self,train):\n",
    "        super().__init__()\n",
    "        self.train=train\n",
    "\n",
    "        # Read the file names and labels\n",
    "        self.label=[]\n",
    "        self.image_path=[]\n",
    "        if self.train:\n",
    "            with open(\"./stl-10/train.json\",\"r\") as f:\n",
    "                file_label_dict=json.load(f)\n",
    "        else:\n",
    "            with open(\"./stl-10/test.json\",\"r\") as f:\n",
    "                file_label_dict=json.load(f)\n",
    "        for data_dict in file_label_dict:\n",
    "            self.image_path.append(data_dict[\"file\"])\n",
    "            self.label.append(data_dict[\"label\"])\n",
    "        \n",
    "        # define the data transforms\n",
    "        # NOTE add your implementation of train / test transforms\n",
    "        if train:\n",
    "            self.transform = None\n",
    "        else:\n",
    "            self.transform=None\n",
    "    def __len__(self):\n",
    "        # NOTE add your implementation to return the length of the dataset\n",
    "        return None\n",
    "    def __getitem__(self, index):\n",
    "        # NOTE add your implementation to return the item\n",
    "        return None\n",
    "    \n",
    "# NOTE add your implementation to cretae STL-10 dataset\n",
    "train_dataset = None\n",
    "test_dataset = None\n",
    "\n",
    "# NOTE add your implementation to create data loaders\n",
    "train_loader = None \n",
    "test_loader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the Lightweight CNN Model\n",
    "\n",
    "Define a lightweight CNN model for image classification with additional layers and techniques for improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# Define the CNN model\n",
    "class LightweightCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LightweightCNN, self).__init__()\n",
    "        self.conv_bn1 = nn.Sequential(nn.Conv2d(3, 48, 3, padding=1),nn.BatchNorm2d(48))\n",
    "        self.conv_bn2_1 = nn.Sequential(nn.Conv2d(48, 96, 3, padding=1),nn.BatchNorm2d(96))\n",
    "        self.conv_bn2_2 = nn.Sequential(nn.Conv2d(96, 96, 3, padding=1),nn.BatchNorm2d(96))\n",
    "        self.conv_bn2_res=nn.Sequential(nn.Conv2d(48,96,1,stride=2),nn.BatchNorm2d(96))\n",
    "        self.conv_bn3_1 = nn.Sequential(nn.Conv2d(96, 192, 3, padding=1),nn.BatchNorm2d(192))\n",
    "        self.conv_bn3_2 = nn.Sequential(nn.Conv2d(192, 192, 3, padding=1),nn.BatchNorm2d(192))\n",
    "        self.conv_bn3_res=nn.Sequential(nn.Conv2d(96,192,1,stride=2),nn.BatchNorm2d(192))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.avg_pool=nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(192, 768)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(768, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv_bn1(x)))\n",
    "        x_res=self.conv_bn2_res(x)\n",
    "        x = self.pool(F.relu(self.conv_bn2_1(x)))\n",
    "        x=self.conv_bn2_2(x)+x_res\n",
    "        x=F.relu(x)\n",
    "        x_res=self.conv_bn3_res(x)\n",
    "        x = self.pool(F.relu(self.conv_bn3_1(x)))\n",
    "        x=self.conv_bn3_2(x)+x_res\n",
    "        x=F.relu(x)\n",
    "        x = self.avg_pool(x).view(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the lightweight CNN model\n",
    "model = LightweightCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train the Model\n",
    "\n",
    "Train the lightweight CNN model using the training dataset with techniques such as learning rate scheduling and model checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "# Define learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)\n",
    "\n",
    "# Train the model\n",
    "model.to(device)\n",
    "num_epochs = 12\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(test_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}')\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save the model if validation loss has decreased\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate the Model\n",
    "\n",
    "Evaluate the performance of the trained model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model = LightweightCNN()\n",
    "best_model.load_state_dict(torch.load('best_model.pth'))\n",
    "best_model.to(device)\n",
    "\n",
    "# Evaluate the model\n",
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run the Code on the Robot\n",
    "\n",
    "1. Save the code in this notebook as a python script (.py file). \n",
    "2. Compress the python script and the dataset.\n",
    "3. Power on the robot, wait untill it fully boots up, and connect your laptop to the WIFI shared by the robot. The password is *hiwonder*\n",
    "4. Using NoMachine to connect to the robot's Linux operating system. Both the username and password are *ubuntu*\n",
    "5. Navigate to */home/ubuntu/COMP8430/*. If the *COMP8430* folder does not exist, create it. Then, create a new folder named after your MQ ID inside *COMP8430*.\n",
    "6. using NomMachine to upload the ZIP file to your folder and then extract its contents.\n",
    "7. Open a terminal in your folder and run the python script using the *python* command.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
